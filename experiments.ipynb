{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from keras import optimizers\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from utils import *\n",
    "from models.GRU import GRU_model\n",
    "from models.GRU_D import create_grud_model, load_grud_model\n",
    "from models.APC import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "with open('datasets/physionet2012.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get class_balance\n",
    "classes_total_dataset = np.concatenate([data[\"train\"][\"y_classes\"], data[\"val\"][\"y_classes\"], data[\"test\"][\"y_classes\"]])\n",
    "class_balance = Counter(classes_total_dataset)\n",
    "class_balance = {c: class_balance[c] / classes_total_dataset.shape[0] for c in class_balance}\n",
    "# get class weights\n",
    "class_weights = get_class_weights(class_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                  patience=5, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRU_experiment(data, class_balance, config, save_model_path, model_name, method = \"class_weights\", class_weights=0):\n",
    "    \n",
    "    K.clear_session()\n",
    "    Path(save_model_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # create model\n",
    "    model = GRU_model(x_length=config[\"x_length\"], \n",
    "                      n_features=config[\"n_features\"], \n",
    "                      n_aux=config[\"n_aux\"], \n",
    "                      n_classes=config[\"n_classes\"], \n",
    "                      n_neurons=config[\"n_neurons\"], \n",
    "                      learning_rate=config[\"learning_rate\"], \n",
    "                      dropout_rate=config[\"dropout_rate\"], \n",
    "                      recurrent_dropout=config[\"recurrent_dropout\"], \n",
    "                      loss_type=config[\"loss_type\"])\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(save_model_path, monitor=config[\"loss_to_monitor\"], verbose=0, save_best_only=True, mode=config[\"monitor_mode\"])\n",
    "    \n",
    "    #train model\n",
    "    #undersample majority class\n",
    "    if method == \"undersample\":\n",
    "        #make training set balanced\n",
    "        X_train, X_train_aux, y_train = make_classes_balanced(data[\"train\"])\n",
    "        history = model.fit([X_train, X_train_aux], \n",
    "                            y_train, \n",
    "                            validation_data=([data[\"val\"][\"X_val\"], data[\"val\"][\"X_aux\"]], data[\"val\"][\"y\"]), \n",
    "                            epochs=config[\"epochs\"], \n",
    "                            callbacks=[reduce_lr, checkpoint], \n",
    "                            batch_size=config[\"batch_size\"], \n",
    "                            verbose=2)\n",
    "    #class weights\n",
    "    elif method == \"class_weights\":\n",
    "        history = model.fit([data[\"train\"][\"X_train\"], data[\"train\"][\"X_aux\"]], data[\"train\"][\"y\"], \n",
    "                            validation_data=([data[\"val\"][\"X_val\"], data[\"val\"][\"X_aux\"]], data[\"val\"][\"y\"]), \n",
    "                            epochs=config[\"epochs\"], \n",
    "                            callbacks=[reduce_lr, checkpoint], \n",
    "                            batch_size=config[\"batch_size\"], \n",
    "                            class_weight=class_weights, \n",
    "                            verbose=2)\n",
    "        \n",
    "    #use oversampling batch generator\n",
    "    elif method == \"oversample\":\n",
    "        print(\"using batch generator\")\n",
    "        #training steps\n",
    "        steps_per_epoch = np.ceil(data[\"train\"][\"X_train\"].shape[0] / batch_size)\n",
    "        # validation steps\n",
    "        validation_steps= np.ceil(data[\"val\"][\"X_val\"].shape[0] /batch_size)\n",
    "        \n",
    "        training_generator = oversample_batch_generator_GRU(data[\"train\"], class_balance, config[\"epochs\"], config[\"batch_size\"])\n",
    "        validation_generator = batch_generator_GRU(data[\"val\"], config[\"batch_size\"])\n",
    "        history = model.fit_generator(generator=training_generator, \n",
    "                                      validation_data=validation_generator,\n",
    "                                      epochs = config[\"epochs\"],\n",
    "                                      steps_per_epoch = steps_per_epoch,\n",
    "                                      validation_steps = validation_steps,\n",
    "                                      callbacks=[reduce_lr, checkpoint],  \n",
    "                                      verbose=2)\n",
    "  \n",
    "    #load best weights\n",
    "    model.load_weights(save_model_path)\n",
    "    \n",
    "    # get results\n",
    "    yhat_test = model.predict([data[\"text\"][\"X_test\"], data[\"test\"][\"X_aux\"]], verbose=1)\n",
    "    y_pred_test = [np.argmax(y, axis=None, out=None) for y in yhat_test]\n",
    "    y_test_ = [np.argmax(y, axis=None, out=None) for y in y_test]\n",
    "\n",
    "    results = get_results_df(y_test_, y_pred_test, y_test, yhat_test, model_name, config[\"n_classes\"])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"x_length\": 48,\n",
    "          \"n_neurons\": 64,\n",
    "          \"learning_rate\": 1e-3, \n",
    "          \"dropout_rate\": 0.0,\n",
    "          \"recurrent_dropout\": 0.0,\n",
    "          \"n_features\": 74,\n",
    "          \"n_aux\": 9,\n",
    "          \"n_classes\": 2,\n",
    "          \"loss_type\": \"binary_crossentropy\",\n",
    "          \"loss_to_monitor\": \"val_auprc\",\n",
    "          \"monitor_mode\": \"max\",\n",
    "          \"epochs\": 50, \n",
    "          \"batch_size\": 32\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### undersample majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add save best model path\n",
    "GRU_undersamp_model_path = \"saved_models/GRU_undersampling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_experiment(data, class_balance, config, GRU_undersamp_model_path, \"GRU_undersampling\", method=\"undersample\", class_weights=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add save best model path\n",
    "GRU_cw_model_path = \"saved_models/GRU_cw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_experiment(data, class_balance, config, GRU_cw_model_path, \"GRU_cw\", method=\"class_weights\", class_weights=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### oversample minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add save best model path\n",
    "GRU_over_model_path = \"saved_models/GRU_oversampling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_experiment(data, class_balance, config, GRU_over_model_path, \"GRU_oversampling\", method=\"oversample\", class_weights=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU - D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"x_length\": 48,\n",
    "          \"n_neurons\": 32,\n",
    "          \"learning_rate\": 1e-3, \n",
    "          \"dropout_rate\": 0.1,\n",
    "          \"recurrent_dropout\": 0.0,\n",
    "          \"n_features\": 37,\n",
    "          \"n_aux\": 9,\n",
    "          \"n_classes\": 2,\n",
    "          \"loss_type\": \"binary_crossentropy\",\n",
    "          \"loss_to_monitor\": \"val_auprc\",\n",
    "          \"monitor_mode\": \"max\",\n",
    "          \"epochs\": 50, \n",
    "          \"batch_size\": 32,\n",
    "          \"eval_metric\": auprc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRU_ext_experiment(data, config, save_model_path, class_weights, predefined_model = \"GRUD\"):\n",
    "    K.clear_session()\n",
    "    Path(save_model_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    #create model\n",
    "    GRU_ext = create_grud_model(input_dim=config[\"n_features\"],\n",
    "                                aux_dim=config[\"n_aux\"],\n",
    "                              hidden_neurons=config[\"n_neurons\"],\n",
    "                              dropout_rate=config[\"dropout_rate\"], \n",
    "                              recurrent_dropout_rate=config[\"recurrent_dropout_rate\"],\n",
    "                              output_dim=config[\"n_classes\"],\n",
    "                              predefined_model=predefined_model)\n",
    "\n",
    "    #compile model\n",
    "    adam_optim = optimizers.Adam(lr=config[\"learning_rate\"]) \n",
    "    model.compile(loss=config[\"loss_type\"], optimizer=adam_optim, metrics=[config[\"eval_metric\"]])\n",
    "    \n",
    "    #save best weights\n",
    "    checkpoint = ModelCheckpoint(save_model_path, monitor=config[\"loss_to_monitor\"], verbose=0, save_best_only=True, save_weights_only=True, mode=config[\"monitor_mode\"])\n",
    "    \n",
    "    print(\"using batch generator\")\n",
    "    #training steps\n",
    "    train_steps_per_epoch = np.ceil(data[\"train\"][\"X\"].shape[0] / config[\"batch_size\"])\n",
    "    # validation steps\n",
    "    validation_steps= np.ceil(data[\"val\"][\"X\"].shape[0] / config[\"batch_size\"])\n",
    "    #train\n",
    "    training_generator = batch_generator_GRUD(data[\"train\"], config[\"batch_size\"])\n",
    "    validation_generator = batch_generator_GRUD(data[\"val\"], config[\"batch_size\"])\n",
    "    history = model.fit_generator(generator=training_generator, \n",
    "                                  validation_data=validation_generator,\n",
    "                                  epochs = config[\"epochs\"],\n",
    "                                  steps_per_epoch = steps_per_epoch,\n",
    "                                  validation_steps = validation_steps,\n",
    "                                  callbacks=[reduce_lr, checkpoint],  \n",
    "                                  class_weight=class_weights, \n",
    "                                  verbose=2)\n",
    "    #load best weights\n",
    "    model.load_weights(save_model_path)\n",
    "    \n",
    "    test_steps_per_epoch = np.ceil(data[\"test\"][\"X\"].shape[0] / config[\"batch_size\"])\n",
    "    \n",
    "    y_test_pred = model.predict_generator(batch_generator_GRUD(data[\"test\"], config[\"batch_size\"]), steps=test_steps_per_epoch)\n",
    "    \n",
    "    y_pred_test_ = [np.argmax(y, axis=None, out=None) for y in y_test_pred]\n",
    "    y_test_ = [np.argmax(y, axis=None, out=None) for y in data[\"test\"][\"y\"]]\n",
    "\n",
    "    results = get_results_df(y_test_, y_pred_test_, y_test, y_test_pred, predefined_model, config[\"n_classes\"])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = \"saved_models/GRUD_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_ext_experiment(data, config, save_model_path, class_weights, predefined_model = \"GRUD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU - Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = \"saved_models/GRUD_mean_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_ext_experiment(data, config, save_model_path, class_weights, predefined_model = \"GRUmean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU - Forward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = \"saved_models/GRUD_forward_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_ext_experiment(data, config, save_model_path, class_weights, predefined_model = \"GRUforward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU - Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = \"saved_models/GRUD_simple_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_ext_experiment(data, config, save_model_path, class_weights, predefined_model = \"GRUsimple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU - APC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def APC_experiment(data, encoder, config, class_weights, save_weights_path, step=1, stop_APC_grad=False):\n",
    "\n",
    "    K.clear_session()  \n",
    "    Path(save_weights_path).mkdir(parents=True, exist_ok=True)\n",
    "      \n",
    "    model = create_APC_classifier(config, encoder, stop_APC_grad)\n",
    "    if config[\"pre_trained_weights\"] != 0:\n",
    "        model.load_weights(config[\"pre_trained_weights\"])\n",
    "    \n",
    "    \n",
    "    #train model\n",
    "    #training steps\n",
    "    train_steps_per_epoch = np.ceil(data[\"train\"][\"X\"].shape[0] / config[\"batch_size\"])\n",
    "    # validation steps\n",
    "    validation_steps= np.ceil(data[\"val\"][\"X\"].shape[0]/ config[\"batch_size\"])\n",
    "    \n",
    "    # add checkpoint to save best model weights\n",
    "    checkpoint = ModelCheckpoint(save_weights_path, save_weights_only=True, monitor=config[\"loss_to_monitor\"], verbose=0, save_best_only=True, mode=config[\"monitor_mode\"])\n",
    "    \n",
    "    if encoder == \"GRU\":\n",
    "        training_generator = APC_batch_generator(data[\"train\"], config[\"time_shift\"], config[\"batch_size\"])\n",
    "        validation_generator = APC_batch_generator(data[\"val\"], config[\"time_shift\"], config[\"batch_size\"])\n",
    "    elif encoder == \"GRUD\":\n",
    "        training_generator = APC_GRUD_batch_generator(data[\"train\"], config[\"time_shift\"], config[\"batch_size\"])\n",
    "        validation_generator = APC_GRUD_batch_generator(data[\"val\"], config[\"time_shift\"], config[\"batch_size\"])\n",
    "\n",
    "    history = model.fit_generator(generator=training_generator, \n",
    "                                  validation_data=validation_generator,\n",
    "                                  epochs = config[\"epochs\"],\n",
    "                                  steps_per_epoch = train_steps_per_epoch,\n",
    "                                  validation_steps = validation_steps,\n",
    "                                  callbacks=[reduce_lr, checkpoint], \n",
    "                                  class_weight={ 'output_1': {0: 1 , 1: 1} , 'output_2': class_weights},  \n",
    "                                  verbose=2)\n",
    "    if step == 1:\n",
    "        #pretraining step\n",
    "        return print(\"done training.\")\n",
    "    \n",
    "    else: # step 2 or 3\n",
    "        # load best weights\n",
    "        model.load_weights(save_weights_path)\n",
    "        \n",
    "        test_steps_per_epoch = np.ceil(data[\"text\"][\"X\"].shape[0] / config[\"batch_size\"])\n",
    "        \n",
    "        if encoder == \"GRU\":\n",
    "            _, y_pred = model.predict_generator(APC_batch_generator(data[\"test\"], config[\"time_shift\"], config[\"batch_size\"]), steps=test_steps_per_epoch)\n",
    "        elif encoder == \"GRUD\":\n",
    "            test_generator = APC_GRUD_batch_generator(data[\"test\"], config[\"time_shift\"], config[\"batch_size\"])\n",
    "            class_pred, actual_classes = [], []\n",
    "            i = 0\n",
    "            for batch in test_generator:\n",
    "                if i < (steps_per_epoch + 1):\n",
    "                    actual_classes.append(batch[1])\n",
    "                    r, c = model.predict_on_batch(batch[0])\n",
    "                    class_pred.append(c)\n",
    "                    i += 1\n",
    "                else:\n",
    "                    break\n",
    "                    \n",
    "            y_test = [x[1] for i, x in enumerate(actual_classes)]\n",
    "            y_test = np.vstack(y_test)\n",
    "            y_pred = np.vstack(class_pred)\n",
    "            \n",
    "        y_pred_classes = [np.argmax(y, axis=None, out=None) for y in y_pred]\n",
    "        y_test_classes = [np.argmax(y, axis=None, out=None) for y in y_test]\n",
    "        model_name = encoder + \"- APC\"\n",
    "        results = get_results_df(y_test_classes, y_pred_classes, y_test, y_pred, model_name, config[\"n_classes\"])\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"n_features\": 74,\n",
    "                  \"n_neurons\": 64,\n",
    "                  \"learning_rate\": 1e-03,\n",
    "                  \"aux_dim\": 9,\n",
    "                  \"n_classes\": 2,\n",
    "                  \"dropout_rate\": 0.0,\n",
    "                  \"recurrent_dropout_rate\": 0.0,\n",
    "                  \"batch_size\": 32,\n",
    "                  \"epochs\": 100,\n",
    "                  \"l1\": 1,\n",
    "                  \"l2\": 0,\n",
    "                  \"l1_type\": masked_mse\n",
    "                  \"l2_type\": 'binary_crossentropy',\n",
    "                  \"evaluation_metric\": auprc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add/change time_shift_factor n\n",
    "# we run our experiments for n = 0 (autoencoder), 1, 2, 3, 4 & 5\n",
    "time_shift_factor = 1\n",
    "config[\"time_shift\"] = time_shift_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Pre-train APC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add save best model path\n",
    "APC_step1_weights_path = \"apc_models/APC_step1_n{}_weights_{}\".format(time_shift_factor, encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"l1\"] = 1\n",
    "config[\"l2\"] = 0\n",
    "config[\"epochs\"] = 100\n",
    "config[\"pre_trained_weights\"] = 0\n",
    "\n",
    "config[\"loss_to_monitor\"] = \"val_loss\"\n",
    "config[\"monitor_mode\"] = \"min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APC_experiment(data, \"GRU\", config, class_weights, 0, step=1, stop_APC_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Frozen: Train classifier with frozen APC weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"l1\"] = 0\n",
    "config[\"l2\"] = 1\n",
    "config[\"learning_rate\"] = 1e-4\n",
    "config[\"pre_trained_weights\"] = APC_step1_weights_path\n",
    "\n",
    "config[\"loss_to_monitor\"] = \"val_dense_3_auprc\"\n",
    "config[\"monitor_mode\"] = \"max\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APC_step2_weights_path = \"apc_models/APC_step2_n{}_weights_{}\".format(time_shift_factor, encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APC_step2_results = APC_experiment(data, \"GRU\", config, class_weights, APC_step2_weights_path, step=2, stop_APC_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Fine-tuned: Train APC + classifier end-to-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"l1\"] = 1\n",
    "config[\"l2\"] = 1\n",
    "config[\"pre_trained_weights\"] = APC_step2_weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APC_step3_weights_path = \"apc_models/APC_step3_n{}_weights_{}\".format(time_shift_factor, encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APC_step3_results = APC_experiment(data, \"GRU\", config, class_weights, APC_step3_weights_path, step=3, stop_APC_grad=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
